{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I am using this data to build a model to predict cars that will be fuel efficient\n",
    "EPA Site says average mpg for now is 24.7 lets say anything over 25 is fuel efficient for the purposes of this model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('C:\\\\Users\\halln\\Desktop\\THINKFUL\\Datasets\\MPG_Prediction\\mpg.csv')\n",
    "# Drop ? entries from horsepower and convert from object to integers \n",
    "data = data[data['horsepower']!='?']\n",
    "data['horsepower'] = data.loc[:,'horsepower'].apply(lambda x: int(x))\n",
    "# Create binary indicator showing if cars are fuel efficient (eg. mpg >= 25)\n",
    "data['Fuel_Efficient?'] = data.loc[:,'mpg'] >= 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Collect variables of interest for regression\n",
    "Y = pd.DataFrame(data['mpg'])\n",
    "X = pd.DataFrame(data[['cylinders','displacement','horsepower','weight','acceleration','model_year']])\n",
    "len(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First using linear regressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=10, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize each regression\n",
    "ols_reg = linear_model.LinearRegression()\n",
    "rid_reg = linear_model.Ridge(alpha=10)\n",
    "las_reg = linear_model.Lasso(alpha=10)\n",
    "\n",
    "# Fit trendlines to data\n",
    "ols_reg.fit(X,Y)\n",
    "rid_reg.fit(X,Y)\n",
    "las_reg.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "FOR AN ORDINARY LEAST SQUARES REGRESSION:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Coefficients:\n",
      " [[-3.29859089e-01  7.67843024e-03 -3.91355574e-04 -6.79461791e-03\n",
      "   8.52732469e-02  7.53367180e-01]]\n",
      "\n",
      "Intercept: [-14.53525048]\n",
      "\n",
      "R^2 Value: 0.8092552890383933\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR A RIDGE REGRESSION:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Coefficients:\n",
      " [[-3.01912329e-01  7.23504980e-03 -4.39605739e-04 -6.79524484e-03\n",
      "   8.46899991e-02  7.51637411e-01]]\n",
      "\n",
      "Intercept: [-14.45457602]\n",
      "\n",
      "R^2 Value: 0.8092511787858475\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR A LASSO REGRESSION:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Coefficients:\n",
      " [-0.         -0.00625887 -0.01545317 -0.00630863  0.          0.        ]\n",
      "\n",
      "Intercept: [45.06157478]\n",
      "\n",
      "R^2 Value: 0.7028782188969025\n"
     ]
    }
   ],
   "source": [
    "print('-'*100)\n",
    "print('''FOR AN ORDINARY LEAST SQUARES REGRESSION:''')\n",
    "print('-'*100)\n",
    "print(\"Coefficients:\\n\",ols_reg.coef_)\n",
    "print(\"\\nIntercept:\",ols_reg.intercept_)\n",
    "print(\"\\nR^2 Value:\",ols_reg.score(X,Y))\n",
    "\n",
    "print('-'*100)\n",
    "print('''FOR A RIDGE REGRESSION:''')\n",
    "print('-'*100)\n",
    "print(\"Coefficients:\\n\",rid_reg.coef_)\n",
    "print(\"\\nIntercept:\",rid_reg.intercept_)\n",
    "print(\"\\nR^2 Value:\",rid_reg.score(X,Y))\n",
    "\n",
    "print('-'*100)\n",
    "print('''FOR A LASSO REGRESSION:''')\n",
    "print('-'*100)\n",
    "print(\"Coefficients:\\n\",las_reg.coef_)\n",
    "print(\"\\nIntercept:\",las_reg.intercept_)\n",
    "print(\"\\nR^2 Value:\",las_reg.score(X,Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " regression models all have decent fit but all could definitely be imporoved upon, lets try logistic regressions next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect variables of interest for regression\n",
    "Y = np.array(data['Fuel_Efficient?'])\n",
    "X = pd.DataFrame(data[['cylinders','displacement','horsepower','weight','acceleration','model_year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l1', random_state=None, solver='liblinear',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize each regression\n",
    "log_reg = linear_model.LogisticRegression(solver='liblinear')\n",
    "las_log_reg = linear_model.LogisticRegression(penalty='l1',solver='liblinear')\n",
    "rid_log_reg = linear_model.LogisticRegression(C=1,penalty='l2',solver='liblinear')\n",
    "\n",
    "# Fit trendlines to data\n",
    "log_reg.fit(X,Y)\n",
    "rid_log_reg.fit(X,Y)\n",
    "las_log_reg.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------\n",
      "FOR A LOGISTIC REGRESSION:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Coefficients:\n",
      "[[-0.01312513 -0.00512465 -0.09216219 -0.00271667 -0.32946454  0.28369541]]\n",
      "[-0.02052523]\n",
      "\n",
      " Crosstab\n",
      "col_0  False  True \n",
      "row_0              \n",
      "False    207     16\n",
      "True      19    150\n",
      "\n",
      " Percentage accuracy\n",
      "0.9107142857142857\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR A RIDGE LOGISTIC REGRESSION:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Coefficients:\n",
      "[[-0.01312513 -0.00512465 -0.09216219 -0.00271667 -0.32946454  0.28369541]]\n",
      "[-0.02052523]\n",
      "\n",
      " Crosstab\n",
      "col_0  False  True \n",
      "row_0              \n",
      "False    207     16\n",
      "True      19    150\n",
      "\n",
      " Percentage accuracy\n",
      "0.9107142857142857\n",
      "----------------------------------------------------------------------------------------------------\n",
      "FOR A LASSO LOGISTIC REGRESSION:\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Coefficients:\n",
      "[[ 0.         -0.00531049 -0.09003848 -0.00273448 -0.31346238  0.27769999]]\n",
      "[0.]\n",
      "\n",
      " Crosstab\n",
      "col_0  False  True \n",
      "row_0              \n",
      "False    206     16\n",
      "True      20    150\n",
      "\n",
      " Percentage accuracy\n",
      "0.9081632653061225\n"
     ]
    }
   ],
   "source": [
    "print('-'*100)\n",
    "print('''FOR A LOGISTIC REGRESSION:''')\n",
    "print('-'*100)\n",
    "print('Coefficients:')\n",
    "print(log_reg.coef_)\n",
    "print(log_reg.intercept_)\n",
    "pred_1_sklearn = log_reg.predict(X)\n",
    "print('\\n Crosstab')\n",
    "print(pd.crosstab(pred_1_sklearn, Y))\n",
    "print('\\n Percentage accuracy')\n",
    "print(log_reg.score(X, Y))\n",
    "\n",
    "print('-'*100)\n",
    "print('''FOR A RIDGE LOGISTIC REGRESSION:''')\n",
    "print('-'*100)\n",
    "print('Coefficients:')\n",
    "print(rid_log_reg.coef_)\n",
    "print(rid_log_reg.intercept_)\n",
    "pred_2_sklearn = rid_log_reg.predict(X)\n",
    "print('\\n Crosstab')\n",
    "print(pd.crosstab(pred_2_sklearn, Y))\n",
    "print('\\n Percentage accuracy')\n",
    "print(rid_log_reg.score(X, Y))\n",
    "\n",
    "print('-'*100)\n",
    "print('''FOR A LASSO LOGISTIC REGRESSION:''')\n",
    "print('-'*100)\n",
    "print('Coefficients:')\n",
    "print(las_log_reg.coef_)\n",
    "print(las_log_reg.intercept_)\n",
    "pred_3_sklearn = las_log_reg.predict(X)\n",
    "print('\\n Crosstab')\n",
    "print(pd.crosstab(pred_3_sklearn, Y))\n",
    "print('\\n Percentage accuracy')\n",
    "print(las_log_reg.score(X, Y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results between the regression models are pretty comparable - most likely due to the fact that this is a relatively small dataset and that all of the regression models produce accurate results for the model.  The effects from ridge and lasso regressions would most likely be more pronounced when working with a larger dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "392"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
